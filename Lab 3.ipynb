{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DcayLcTltUeT"
   },
   "source": [
    "<center>\n",
    "<h1>\n",
    "<h1>APM 53674: ALTeGraD</h1>\n",
    "<h2>Lab Session 3: Improving LLMs with RLHF (DPO & GRPO)</h2>\n",
    "<h4>Lecture: Prof. Michalis Vazirgiannis<br>\n",
    "Lab: Yang Zhang and Xiao Fei</h4>\n",
    "<h5>Tuesday, October 14, 2025</h5>\n",
    "<br>\n",
    "</center>\n",
    "\n",
    "<hr style=\"border:10px solid gray\"> </hr>\n",
    "<p style=\"text-align: justify;\">\n",
    "This handout includes theoretical introductions, <font color='blue'>coding tasks</font> and <font color='red'>questions</font>. Before the deadline, you should submit <a href='https://forms.gle/9dyaes6dimfvyjwq6' target=\"_blank\">here</a> a <B>.ipynb</B> file named <b>Lastname_Firstname.ipynb</b> containing your notebook (with the gaps filled and your answers to the questions). Your answers should be well constructed and well justified. They should not repeat the question or generalities in the handout. When relevant, you are welcome to include figures, equations and tables derived from your own computations, theoretical proofs or qualitative explanations. One submission is required for each student. The deadline for this lab is <b>October 19\n",
    ", 2025 11:59 PM</b>. No extension will be granted. Late policy is as follows: ]0, 24] hours late ‚Üí -5 pts; ]24, 48] hours late ‚Üí -10 pts; > 48 hours late ‚Üí not graded (zero).\n",
    "</p>\n",
    "<hr style=\"border:5px solid gray\"> </hr>\n",
    "\n",
    "\n",
    "# ü§ñ Post-Training: Improving LLMs with RLHF (DPO & GRPO)\n",
    "\n",
    "In this notebook, we‚Äôll show how to improve a language model using **two post-training techniques**:\n",
    "\n",
    "### üß† What You‚Äôll Learn\n",
    "- What **Direct Preference Optimization (DPO)** is and how it helps models choose better answers.\n",
    "- What **Group Relative Policy Optimization (GRPO)** is and how it helps models solve tasks  improving reasoning and performance on complex tasks (math, code, logic).\n",
    "- How to train small models on **real feedback data**.\n",
    "- How to **observe changes in model behavior** after fine-tuning.\n",
    "\n",
    "\n",
    "### üì¶ What We‚Äôll Use\n",
    "- **Hugging Face ü§ó Transformers** to load and run models\n",
    "- **TRL (Transformer Reinforcement Learning)** library by Hugging Face ü§ó for DPO and GRPO\n",
    "- **A small version** of the French translated [Anthropic HH-RLHF dataset](https://huggingface.co/datasets/AIffl/french_hh_rlhf)\n",
    "- **Colab GPU**, so models are small enough to run quickly\n",
    "\n",
    "### Useful links:\n",
    "- [Hugging Face ü§ó DPO Trainer](https://huggingface.co/docs/trl/dpo_trainer)\n",
    "- [Hugging Face ü§ó GRPO Trainer](https://huggingface.co/docs/trl/grpo_trainer)\n",
    "\n",
    "> This notebook is interactive, friendly, and high-level. You don‚Äôt need to know deep math or theory to follow along."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wH0u4hhtUeV"
   },
   "source": [
    "# Quick start:\n",
    "1-  Clone the repository:\n",
    "```bash\n",
    "git clone https://github.com/BounharAbdelaziz/RLHF.git\n",
    "```\n",
    "2- Install the dependencies:\n",
    "```bash\n",
    "pip install -q -r requirements.txt\n",
    "```\n",
    "Now we are ready to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-7EtCgK2t1lf",
    "outputId": "7b6a164a-7d70-416d-cda8-94297319f72f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NPEWV5M_tUeV",
    "outputId": "20e934c3-528f-44e5-eb76-6f9dbe50f739"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'RLHF'...\n",
      "remote: Enumerating objects: 15, done.\u001b[K\n",
      "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
      "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
      "remote: Total 15 (delta 3), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (15/15), 13.46 KiB | 3.36 MiB/s, done.\n",
      "Resolving deltas: 100% (3/3), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/BounharAbdelaziz/RLHF.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qAXzTCmJtX3s",
    "outputId": "9edd12b2-f8eb-401b-980b-0178cc008113"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m423.1/423.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m60.1/60.1 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q -r RLHF/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_A8MAR6WtUeV"
   },
   "source": [
    "# Part I: DPO\n",
    "\n",
    "# üß† Fine-tuning Qwen2.5-0.5B-Instruct on French Data\n",
    "\n",
    "In this part, we‚Äôll walk through how to **fine-tune the Qwen2.5-0.5B-Instruct** model on **French-language data**, using **off-policy DPO (Direct Preference Optimization)**.\n",
    "\n",
    "---\n",
    "\n",
    "## üß© Key Concepts\n",
    "\n",
    "- **Model**: [Qwen2.5-0.5B-Instruct](https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct)  \n",
    "- **Objective**: Adapt the model for French understanding and instruction-following  \n",
    "- **Method**: Off-policy **DPO** for alignment-based fine-tuning  \n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è System Requirements\n",
    "\n",
    "Before training, make sure you choose an appropriate GPU setup.\n",
    "\n",
    "- **Memory requirements**: [GPU memory guidance](https://rahulschand.github.io/gpu_poor/)  \n",
    "- **GPU options**:\n",
    "  - AWS SageMaker: [pricing calculator](https://aws.amazon.com/sagemaker-ai/pricing/)  \n",
    "  - üí∏ Cheaper alternative: [RunPod](https://www.runpod.io/)  \n",
    "\n",
    "---\n",
    "\n",
    "## üßÆ Memory Optimization\n",
    "\n",
    "We‚Äôll use **LoRA** (Low-Rank Adaptation) combined with **quantization (4-bit)** to reduce GPU memory usage while maintaining performance.\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Evaluation Tools\n",
    "\n",
    "To evaluate the fine-tuned model, you can use one or more of the following frameworks:\n",
    "\n",
    "- [`lm-eval-harness`](https://github.com/EleutherAI/lm-evaluation-harness)\n",
    "- [`lighteval`](https://github.com/huggingface/evaluate)\n",
    "- [`libra-eval`](https://github.com/facebookresearch/libra)\n",
    "\n",
    "---\n",
    "Below is a visual overview of the **Direct Preference Optimization (DPO)** training process:\n",
    "\n",
    "![DPO Training Diagram](https://1drv.ms/i/c/ae69638675180117/IQQ_wS77RKdrS4tzLbwoqr1gAR0Bf_1X2U36NRBp1Odsypg?width=560&height=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "H8AyeUIktUeV"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "from trl import (\n",
    "    DPOTrainer,\n",
    "    DPOConfig,\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "import torch\n",
    "import os\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2czRsmsAQEF4"
   },
   "source": [
    "## üìä Tracking with Weights & Biases (W&B)\n",
    "\n",
    "We‚Äôll use **Weights & Biases (W&B)** to log training metrics, model versions, and system stats so you can compare runs, debug faster, and share results. Before running the next cell, **create a free account** at [https://wandb.ai](https://wandb.ai) and make a new **Project** (e.g., `RLHF`). In the code cell that follows, we‚Äôll initialize W&B; on first use you‚Äôll need to **register** then paste your **API key** from your W&B profile. During training, W&B will automatically track losses, learning rate, gradient norms, and GPU utilization, and we‚Äôll log custom metrics (e.g., validation perplexity, evaluation scores) plus configuration details (dataset, hyperparameters, LoRA/quantization settings). Each run will appear on your project dashboard with charts, tables, run metadata, and artifacts, making it easy to **compare experiments**, **resume runs**, and **share dashboards** with your teammates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vtHPrUXYYVO"
   },
   "source": [
    "<b><h4><font color='blue'>\n",
    "<hr style=\"border:10px solid blue\"> </hr>\n",
    "Task 1: </b><br>\n",
    "Create your Weights&Biases account and fill the gap the next cell.\n",
    "<hr style=\"border:10px solid blue\"> </hr>\n",
    "</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h6J6EMxdtUeV",
    "outputId": "5a635545-09c2-4445-abb9-ad63351bfb91"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
      "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvemz\u001b[0m (\u001b[33mvemz-x\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "# We will use wandb.ai for logging the experiments - Set your API key here\n",
    "WANDB_API_KEY = \"\" # fill the gap with your wandb account\n",
    "\n",
    "# Automatically login using the API key\n",
    "os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY\n",
    "os.environ[\"WANDB_PROJECT\"] = \"RLHF\"\n",
    "wandb.login()\n",
    "\n",
    "# Training dataset\n",
    "DATASET_PATH = \"AIffl/french_orca_dpo_pairs\" # french version of \"Intel/orca_dpo_pairs\"\n",
    "\n",
    "# We limit to 2k samples for speed\n",
    "LIMIT = 2_000\n",
    "\n",
    "# SFT Model we will finetune\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "# Seed for reproducibility\n",
    "SEED = 1998\n",
    "\n",
    "MAX_PROMPT_LEN = 1024\n",
    "MAX_LENGTH = MAX_PROMPT_LEN + 512\n",
    "\n",
    "RUN_NAME = \"DPO-french-orca-\" + MODEL_NAME.split('/')[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NS_Fgnc4tUeW"
   },
   "source": [
    "## Load the SFT Model and Tokenizer\n",
    "\n",
    "We‚Äôll stick with 4-bit quantization via bitsandbytes for this lab. You‚Äôve already used it last week, so nothing new‚Äîsame setup (load the model with 4-bit weights), same goal (reduce VRAM) with minimal impact on quality for our use case. This keeps runs feasible on a single GPU.\n",
    "\n",
    "We will need the tonkenizer in the data preparation step to apply the chat template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzt-X_0mYnEl"
   },
   "source": [
    "<b><h4><font color='blue'>\n",
    "<hr style=\"border:10px solid blue\"> </hr>\n",
    "Task 2: </b><br>\n",
    "Create the quantization confiduration to load the model with 4 bits\n",
    "<hr style=\"border:10px solid blue\"> </hr>\n",
    "</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363,
     "referenced_widgets": [
      "9822c3f9f6e9405cb484f89fe76faace",
      "bd74c8ee94b346a9b95a3d95776a8967",
      "e8044adad2dd4e2dab6cad86a85a5aed",
      "7e5915166c8545e6a4193373d96b8009",
      "aa60a89916a6499ea94a72a593b75d6c",
      "44c28fe869a149cdbbec4417ba604f5b",
      "40915b8d3b2d4014a9856489535ca688",
      "3b6d55d2d5344d2a88f0ba6af4eada81",
      "16f24d701ffe4f19a92cf7bf4373ecff",
      "cf331ecfe4914d36ac69c1e2f986f535",
      "72d305ae5edd4200940cde7ee5b1b129",
      "524e76021e3f4903b336599d136c56e7",
      "e0eb1baed7d14fbfb01043787b851476",
      "a0cdff91eb714237b8a873157aa8c8ac",
      "fa56156add23401cb5c97261da260655",
      "947904f6f7b74f99ad6c3bc7664c7fa4",
      "0d753cba59fa4999ab4171a7235bd968",
      "efeb0a54782f4ddbaddee1cd2847c82d",
      "ea073dbaf7464c48ad41401c4910d214",
      "5fdaa0dfda7c41a4993d3dd617f35c9f",
      "dd1caca3c7c64979b3205955f9aaec3e",
      "a68e8b29059f4f819bd53673b8f55c17",
      "8bf3e762360f4e938b90b10db30c5f38",
      "c9e38582e5dd4b0ab2a1903487bbb030",
      "66b2fec71af74348acd5658b8a0124f4",
      "2d8bc1d4231b442ea84c2d840c019773",
      "37513b9fccf64507820e559a1235dab0",
      "8784b5f0cd0a4aebbf68dc7b49bfe8aa",
      "1800fa6d69994558b3cc31bafa0e1972",
      "731dc3b96bc04bbe8742d5b93bbbd356",
      "0c87102356de4981bbbc98ab78b6d627",
      "d607ff54aaea473e999ae31b66160a34",
      "2ef249a1c420494788568158cd84b874",
      "d38a67dfc86940b396e6fdbab7792887",
      "a18b13d945b543a78a3765f11c9e4a43",
      "053eafc541394386bb1a79f4a6ddce08",
      "b41d1d9a2ca248b18889d781aa4a90ac",
      "e12515b335164beda0490fdc0b584fb3",
      "92860253f61545c2bfbfdecdd3d51a9f",
      "5a09d0d5799749a2a2b2246a73e13711",
      "490084ddf1c544e6988fabc21d920ecd",
      "c53d8a19fca04769aa99e3b9614096f1",
      "dc181dc8ee8a467e8577e3a4639dd197",
      "eb8c916435874574bbc6fd17f4da1ee0",
      "0f617c2960c74c4e9eb94b8225aefedd",
      "182f4a9a2c6145a9952768fedc01421e",
      "641fb64f21304756bf1bfddb6832ae84",
      "a039b25e53224b87a469c72131bf2e4c",
      "ad2cdb7242a2473fb519707de44a840b",
      "a3fef6ce2e0042a09c6e11f9e380a9c3",
      "f6673d955cfb466fa83cab474d1d1cc6",
      "b1ba51a785294d4ca60f50ab1a373f0b",
      "863048087bb843418262aa0ad2108892",
      "4eb67ba28dec433092c4fa1e4f8e9d2b",
      "413f491a17094e3d88a04466f6850130",
      "ae1e99ba54ce425f8a11e4446ef8a586",
      "5de25ae91a84468fbc4ac4df2ad14db6",
      "8a05cdbe332d4cc9a4b9a4a289eb5458",
      "a1a1f7604c8d469caee973db97530654",
      "6947313d1d6c4695a2d3d9ec8c1887ee",
      "299db11fcae8443a95925c7e73c511cf",
      "625fa910177649be9fa89e37ce6a365c",
      "d494026d2123425daec42c405942a7b3",
      "a037ff0717754c80bbb69fa8a63a8c46",
      "10b37e6f2b264dcf989c2c3cb0ecc36e",
      "b8ff46be2290483d98eb8e3f28fb862a",
      "6c0029acdced43339c694aeb0d84af78",
      "af30e838a26f4ed38ece141494a64867",
      "d507efa83c764ee7b8f19bb9266341d6",
      "719a979a4751428791887d020cdad1c8",
      "eee080fc6e5d4f439d22f4030332dc84",
      "21e704a93d824a6091c1a68359462981",
      "0809078168e24970a5d4e16df9ac30bf",
      "3b7f8c70dc0440f08d151835cfc2215b",
      "6e1102f22c3e442a938db2c0edc4a235",
      "173acd678a384d06bdbdeb66c38faf00",
      "de97e8319d2d443eb10ba996c89ef592"
     ]
    },
    "id": "Tx0a87p1tUeW",
    "outputId": "9f26234a-1351-4721-82a3-b16532c4689c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9822c3f9f6e9405cb484f89fe76faace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/659 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "524e76021e3f4903b336599d136c56e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf3e762360f4e938b90b10db30c5f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d38a67dfc86940b396e6fdbab7792887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f617c2960c74c4e9eb94b8225aefedd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae1e99ba54ce425f8a11e4446ef8a586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c0029acdced43339c694aeb0d84af78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Quantization configuration\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\") #fill the gap\n",
    "\n",
    "# Load the model to finetune\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float16,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "# to avoid warning\n",
    "model.config.use_cache = False\n",
    "# Prepare model for k-bit training\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "\n",
    "# Set padding token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Wb1mjaltUeW"
   },
   "source": [
    "## Data Preparation\n",
    "\n",
    "### üí¨ Chat templates & converting data to `messages`\n",
    "\n",
    "Modern instruction-tuned models (including **Qwen2.5-0.5B-Instruct**) expect inputs in a **chat format** and rely on a **tokenizer chat template** to turn structured messages into the exact token sequence the model was trained on. In practice, you should **not** hand-craft special tokens; instead, pass a list of `{role, content}` messages to the tokenizer and let `apply_chat_template(...)` do the right thing.\n",
    "\n",
    "#### Why a chat template?\n",
    "- Ensures your prompts match the **pretraining/finetuning format** (system/user/assistant turns, BOS/EOS, separators).\n",
    "- Minimizes prompt drift across libraries and models.\n",
    "- Makes it easy to add **system instructions** (e.g., ‚ÄúYou are a helpful assistant that answers in French.‚Äù).\n",
    "\n",
    "#### Message structure\n",
    "Each example becomes an ordered list of chat turns:\n",
    "```python\n",
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": \"Tu es un assistant utile. R√©ponds en fran√ßais.\"},\n",
    "  {\"role\": \"user\", \"content\": \"Explique la diff√©rence entre LoRA et le fine-tuning complet.\"},\n",
    "  {\"role\": \"assistant\", \"content\": \"LoRA adapte un petit sous-espace de poids, alors que...\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q3h1j7ezZL4R"
   },
   "source": [
    "<b><h4><font color='blue'>\n",
    "<hr style=\"border:10px solid blue\"> </hr>\n",
    "Task 3: </b><br>\n",
    "Create the user message which is the question field of the dataset.\n",
    "<hr style=\"border:10px solid blue\"> </hr>\n",
    "</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194,
     "referenced_widgets": [
      "e43587804d94473c86034da9d55f27c9",
      "6588832c275a49ee8d02e59ce5f3df83",
      "ba68c4dddb2c4f029344b17c6b484a44",
      "92a2a7aa248f463a9b78e5dd11bc47b6",
      "0d4ea659ce6043c3b3afd2bae076a16d",
      "b67d24057bea4516b2611b94a0eb8e6c",
      "7a4b1c78027d4fbba76cd4b96150d575",
      "87a7849f4a5f4bc5b10d7a1d0bb743cf",
      "170a36e9b2474685a219d54fc472846f",
      "4b47d703f723425da7a5abebc3bf2fa9",
      "5b5da2d859c84f04bb9ae222dca504ae",
      "d33421601d5f449db0a9f10c669e5e3b",
      "e19c74fc5af54aeb913de4959acafb9c",
      "58ce15d768214dcc85170d8a9a365505",
      "64849ba87a67482fae05ec729ac484e1",
      "131af2fdde3e4f8c90480081bd1ca73e",
      "b58b19be3b484e4e9c83c00c90c28f0b",
      "3512109a6cef46019a09e48ecd596a55",
      "6ef671221d1c406d8192eb791d8ccd1b",
      "daa7102fade1477693c158ee169587d3",
      "bb84c9335a1d4ae4a6fd82be69e743de",
      "410cf3af0a6843488f221ea6cf2faaa5",
      "939bcc0bba584929b05e0f1f8bf9a2e7",
      "1f5596a202284a388a6646a02eda1053",
      "5a6bf17b84cd496a892e12bf1c600cbe",
      "bc2e259305e1421bb5a00744b23e0c4b",
      "a2873c11e5f340f2b1b1dfafa973e16b",
      "a1586c44310746e0b4b8349860aba16a",
      "2caa6a235074418e9b67029ab9800bf0",
      "17316659f0504c67a32a79b70ff25dc4",
      "1635f051a308491dbaa1f9b0d07dc6f6",
      "e0211a7a47fd4ab79cce31d4a5908f2a",
      "5435a30ec8a84cd2890b283c637662f8",
      "41b871c3b6e9428da68ebc2f7b3794ab",
      "f746ba5ab3f246d1b5fdfcb5ae65b302",
      "29a793a40688435295800f56169c4dd0",
      "9507f233209842ab906e82051db01099",
      "4a18e02b77444caeb10685e9e03dca34",
      "b88824288ef048408877799f3f657b83",
      "9db52739dc7941a1811aed18a10b636c",
      "b59e4c97423540d1acfe455a617e175a",
      "4e87c64cfa2547e4a00919c4883a2b60",
      "d82bfa899f62485c81059cd5ace36b09",
      "9a865335cf474ddc85f8230384646635",
      "93f3751506864c2c9d1410aac6734b4e",
      "14a20076eb404bb6b6a6b47e4d38bbef",
      "dcc33dd9f37f440fb490beeac6e904b5",
      "4baf2e26745c4475baed023f21c526ed",
      "277f385fd93146a383c962e7c889bb37",
      "ba7969d3002949509242a94559290357",
      "d310436150f04ab288a75a681eb41c5d",
      "0469ebee453f43fb9bd89fc80dd6b8d4",
      "3da67d4e85a24eda9a769a35d86b0b70",
      "ad6ee91173d949938f3c3b19bed213b2",
      "c36c74f55640420c807ed57e304da90a"
     ]
    },
    "id": "oW5vfRm0tUeW",
    "outputId": "b4399782-8d70-41a7-e76a-42aedba39e6d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e43587804d94473c86034da9d55f27c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/468 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d33421601d5f449db0a9f10c669e5e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "french_orca_rlhf.jsonl:   0%|          | 0.00/45.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939bcc0bba584929b05e0f1f8bf9a2e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/12670 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b871c3b6e9428da68ebc2f7b3794ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f3751506864c2c9d1410aac6734b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size after filtering: 1954\n"
     ]
    }
   ],
   "source": [
    "def preprocess_for_dpo(example):\n",
    "    # Format system message if present\n",
    "    messages = []\n",
    "    if example.get('system') and len(example['system'].strip()) > 0:\n",
    "        messages.append({\"role\": \"system\", \"content\": example['system']})\n",
    "\n",
    "    # fill the gap, add user message from the question filed of th\n",
    "    user_message = {\"role\": \"user\", \"content\": example['question']} # fill here\n",
    "    messages.append(user_message)\n",
    "\n",
    "    # Create prompt with generation prompt for DPO\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    # The chosen and rejected should be the assistant responses only\n",
    "    chosen = example['chosen']\n",
    "    rejected = example['rejected']\n",
    "\n",
    "    return {\n",
    "        \"prompt\": prompt,\n",
    "        \"chosen\": chosen,\n",
    "        \"rejected\": rejected,\n",
    "    }\n",
    "\n",
    "# Download the training dataset\n",
    "dataset = load_dataset(DATASET_PATH, split=f\"train\")\n",
    "# shuffle and select a number of samples\n",
    "dataset = dataset.shuffle(True).select(range(LIMIT))\n",
    "\n",
    "# Save columns\n",
    "original_columns = dataset.column_names\n",
    "\n",
    "# Apply the preprocessing function\n",
    "dpo_dataset = dataset.map(\n",
    "    preprocess_for_dpo,\n",
    "    remove_columns=original_columns,\n",
    ")\n",
    "\n",
    "# Filter out examples that are too long\n",
    "def filter_length(example):\n",
    "    prompt_length = len(tokenizer.encode(example['prompt']))\n",
    "    chosen_length = len(tokenizer.encode(example['chosen']))\n",
    "    rejected_length = len(tokenizer.encode(example['rejected']))\n",
    "\n",
    "    return (prompt_length + max(chosen_length, rejected_length)) < MAX_LENGTH\n",
    "\n",
    "dpo_dataset = dpo_dataset.filter(filter_length)\n",
    "\n",
    "print(f\"Dataset size after filtering: {len(dpo_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75nrGIGktUeW"
   },
   "source": [
    "## Model Training\n",
    "\n",
    "Training will mirror last week‚Äôs lab, but we‚Äôll switch from SFT to **off-policy DPO** using the `trl` library. Concretely, we‚Äôll instantiate a **policy model** (trainable) and a **reference model** (frozen) and optimize with the DPO objective so the policy prefers **chosen** over **rejected** responses for the same prompt.\n",
    "\n",
    "### What we‚Äôll use\n",
    "- **TRL**: `DPOConfig`, `DPOTrainer`\n",
    "- **PEFT**: LoRA adapters on top of the base **Qwen2.5-0.5B-Instruct**\n",
    "- **Quantization**: 4-bit (QLoRA-style) to fit on small GPUs\n",
    "- **Logging**: W&B for metrics, configs, and artifacts\n",
    "\n",
    "### Expected dataset columns\n",
    "- `prompt` (or `messages`): the shared context (system+user turns)\n",
    "- `chosen`: assistant reply preferred by annotators\n",
    "- `rejected`: less-preferred reply\n",
    "> If you‚Äôre keeping everything in chat format, we‚Äôll pass lists of `{role, content}` and rely on `tokenizer.apply_chat_template(...)` inside the collator.\n",
    "\n",
    "### Minimal training flow\n",
    "1. Load tokenizer with the **chat template** and enable 4-bit loading of the base model.\n",
    "2. Wrap the model with **LoRA** (target attention/MLP modules).\n",
    "3. Build a `datasets.Dataset` that yields `(prompt/messages, chosen, rejected)`.\n",
    "4. Define `DPOConfig` (batch size, lr, epochs, `beta`, logging/saving/eval cadence).\n",
    "5. Create `DPOTrainer(policy_model, ref_model, tokenizer, train_dataset, eval_dataset, **config)`.\n",
    "6. Call `trainer.train()`; optional `trainer.evaluate()` and `trainer.save_model()`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNKXz-pbaj0l"
   },
   "source": [
    "<b><h4><font color='blue'>\n",
    "<hr style=\"border:10px solid blue\"> </hr>\n",
    "Task 4: </b><br>\n",
    "Create the lora config with rank of 32, alpha of 64 and dropout of 0.1 on all MLP layers (execluding Embedding layers) and train the model\n",
    "<hr style=\"border:10px solid blue\"> </hr>\n",
    "</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "5e5c0f259112492785502506978cc7fa",
      "888b82ba8cf447b9a9cd8b670a6802b2",
      "b41b6060877e49da95ab847d4106ddb2",
      "90e82cec044e416bada9e01cd1b55807",
      "5205c929e5a74023b97533744dc8b1d5",
      "35907f3e51894bc492586c460ce08d57",
      "3e35ea2bfd76410db5b0b2fbb8a12205",
      "9ce561f272ec4c458d01932d0c730bed",
      "aafdb5c4cce244f1b5b64589ae1a4023",
      "d5b10eaf0c964c2ba7edb6411cf14add",
      "894da376c5d04a30ac6de36086f5634c",
      "4a9c53a2b07c4294a483f939fc3635e0",
      "d78545230dd5466286583c3c7507cfcb",
      "421a161916d745fc8b81a3bec4c9ae24",
      "e05ccfcee2804a26b5f721c5aa053edf",
      "7866133af7be4509b53f1078981c7080",
      "e29ba5f4ee14495dbd22e2129de56148",
      "a7d44a2cde3c483ba43ed21063707b3b",
      "93b4a8eb66ee459a9b7db204b1c9fda1",
      "291dee0d9a414c209e5e88fa70bb1228",
      "308e977f8169448691b541b89bd0e994",
      "638a6cb5eb8944d3a727f67c43b9fba2",
      "908596adcbf643eb8b5f0af200c6eebb",
      "920edab7600348a48dd90a7d8da76230",
      "f8449ece540e4085b91fa2e270c4f5fb",
      "a710712c8cc54d5f954a3db84ee42243",
      "8391dd7ee2b94ad188bdd9cee663c105",
      "4f5319e0232a47e38847b756c19fa841",
      "a1febacab383440cacf53b0961a9f14d",
      "c80aceea1daf4e54bd9aaec13c28f4d0",
      "b7506166394f40fd87492b4755ecbf87",
      "0f7df71fa8c441868998b1e0fb7c10c4",
      "92f9790e0fef48e6ac94a2ee3d959db3"
     ]
    },
    "id": "jJeBW-l6tUeW",
    "outputId": "0c0e78a1-a2aa-4624-b730-46cc94ce951f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 17,596,416 || all params: 511,629,184 || trainable%: 3.4393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/peft/tuners/lora/bnb.py:348: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:196: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5c0f259112492785502506978cc7fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting prompt in train dataset:   0%|          | 0/1954 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9c53a2b07c4294a483f939fc3635e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/1954 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "908596adcbf643eb8b5f0af200c6eebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/1954 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample from dataset:\n",
      "Prompt: <|im_start|>system\n",
      "Vous √™tes un assistant utile, qui fournit toujours des explications. Pensez comme si vous r√©pondiez √† un enfant de cinq ans.<|im_end|>\n",
      "<|im_start|>user\n",
      "Pr√©misse:\n",
      "\"pour les drogues, ils appliquent la peine de mort pour √ßa, euh, ils sont juste tr√®s tr√®s durs et je suppose que c'est peut-√™tre comme √ßa √† Tokyo ou au Japon aussi, ils sont juste tr√®s durs avec les criminels\" Bas√©e sur cette pr√©misse, c'est l'hypoth√®se \"Pour les drogues, ils appliquent la peine de mort, mais ils sont tr√®s tr√®s durs envers les criminels et c'est peut-√™tre la m√™me chose √† Tokyo ou au Japon.\" vrai?\n",
      "Choisissez votre r√©ponse parmi¬†:\n",
      "[1]. Oui;\n",
      "[2]. il n'est pas possible de le savoir¬†;\n",
      "[3]. Non;<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "Chosen: [1]. Oui\n",
      "Rejected: Ohh ! Laissez-moi y r√©fl√©chir comme un assistant super sympa et intelligent¬†! ü§î\n",
      "\n",
      "Donc, vous dites que certains endroits, comme Tokyo ou le Japon, sont tr√®s durs envers les gens qui font de mauvaises choses, comme la drogue ? üòï Et ils pourraient m√™me leur donner la peine de mort ? üíÄ C'est super duper bad, non ? üò±\n",
      "\n",
      "Eh bien, il est vrai que certains endroits ont des lois tr√®s strictes et punissent tr√®s durement les personnes qui commettent de mauvaises choses. Mais ce n'est pas toujours le cas o√π ils imposent la peine de mort pour la drogue. üôÖ‚Äç‚ôÇÔ∏è Certains endroits ont des lois et des sanctions diff√©rentes pour diff√©rentes choses. ü§ì\n",
      "\n",
      "Ainsi, l‚Äôhypoth√®se selon laquelle ¬´ pour les drogues, ils appliquent la peine de mort, ils sont simplement tr√®s tr√®s durs envers les criminels et cela pourrait √™tre ainsi √† Tokyo ou au Japon ¬ª n‚Äôest pas enti√®rement vraie. üö´ Il n'est pas toujours vrai que les endroits dot√©s de lois et de sanctions strictes en mati√®re de drogue appliquent √©galement la peine de mort. üíî\n",
      "\n",
      "Mais il est important de se rappeler que les lois et les sanctions peuvent varier consid√©rablement d'un endroit √† l'autre, et il est toujours pr√©f√©rable d'√™tre prudent et de suivre les r√®gles ! üòä\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20251019_123005-ai2tr7gp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vemz-x/RLHF/runs/ai2tr7gp' target=\"_blank\">DPO-french-orca-Qwen2.5-0.5B-Instruct</a></strong> to <a href='https://wandb.ai/vemz-x/RLHF' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vemz-x/RLHF' target=\"_blank\">https://wandb.ai/vemz-x/RLHF</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vemz-x/RLHF/runs/ai2tr7gp' target=\"_blank\">https://wandb.ai/vemz-x/RLHF/runs/ai2tr7gp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Detected [huggingface_hub.inference, openai] in use.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/\n",
      "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='489' max='489' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [489/489 30:28, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.691200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.687800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.688100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.685800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.684000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.682800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.664900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.658300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.659500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.635400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.690500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.658400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.562900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.535300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.643200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.551600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.526500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.574600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.432900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.528500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.533000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.465800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.399800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.329500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.350200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.362900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.547300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.302800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.366100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.249400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.555100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.091800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.219100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.121800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.329600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.167800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.121300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.310800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.606300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.220400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.173000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.289500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.238500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.449100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.190500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.169400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.410600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.269800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.418000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.311500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.257500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.083000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.089700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.927200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.105600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.019600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.618500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.373300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.096100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.100900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.406600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.034600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.125900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.350400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.048500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.122900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.420600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.127300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.153400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.173600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.471200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.077500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.042600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.065300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.171400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.057300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.340100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.039400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.251600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.341900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.069700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.518800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.068600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.114900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.003300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.051400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.004300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.330500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.266600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.115200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.090400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.284600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.119400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.106500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>0.209700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.133500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>0.067900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.086800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.033300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>0.045900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.078800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>0.013700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.157300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>0.005400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>0.137700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>0.007500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.229400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>0.001300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>0.161300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>0.298900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>0.176400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>0.128600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.020200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>0.005400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>0.425900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>0.953600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0.168100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.039400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>0.110100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>0.002600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>0.065900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.210800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>0.039500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>0.155800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>0.624600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>0.014800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.127800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>0.176800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>0.063800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>0.017400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>0.108800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.028700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>0.041600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>0.217100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>0.295800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>0.112000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>0.072400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>0.020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>0.022700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>0.049500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.004800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>0.168600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>0.002700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>0.018000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>0.013000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>0.026700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>0.027700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>0.489300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>0.357100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.017700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>0.051900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>0.053700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>0.021600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>1.036000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>0.013700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>0.041400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>1.322800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>0.009300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>0.350100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.000800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>0.027400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>0.063200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>0.124700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>0.485800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.021300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>0.002200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>0.001300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>0.515000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.036500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>0.033300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>0.174100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>0.072000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>0.003200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>0.062100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>0.084100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.034000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>0.000700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.011500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>0.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>0.000800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>0.015500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>0.097300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>0.001300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.045100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>202</td>\n",
       "      <td>0.120400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203</td>\n",
       "      <td>0.079400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>0.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>0.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206</td>\n",
       "      <td>1.148700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207</td>\n",
       "      <td>0.004300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>209</td>\n",
       "      <td>0.141000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.008800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>212</td>\n",
       "      <td>0.044100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213</td>\n",
       "      <td>0.034100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214</td>\n",
       "      <td>1.547400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>0.028900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>217</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>219</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.036200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>221</td>\n",
       "      <td>0.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>222</td>\n",
       "      <td>0.090900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>223</td>\n",
       "      <td>0.008500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>1.061600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.167700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>226</td>\n",
       "      <td>0.278500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227</td>\n",
       "      <td>0.008800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228</td>\n",
       "      <td>0.065400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>229</td>\n",
       "      <td>0.010500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>231</td>\n",
       "      <td>0.329800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>232</td>\n",
       "      <td>0.004700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>233</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>234</td>\n",
       "      <td>0.014700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>0.002200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236</td>\n",
       "      <td>0.004400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>237</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>0.456500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>239</td>\n",
       "      <td>0.225500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.014900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>241</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>242</td>\n",
       "      <td>0.008400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>243</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>244</td>\n",
       "      <td>0.215400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>0.009100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>0.005500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247</td>\n",
       "      <td>0.266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>0.004600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>251</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>0.053700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>0.312100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>254</td>\n",
       "      <td>0.181800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>0.024900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257</td>\n",
       "      <td>0.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258</td>\n",
       "      <td>0.443600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>259</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>261</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>262</td>\n",
       "      <td>0.003300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>263</td>\n",
       "      <td>0.859100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264</td>\n",
       "      <td>0.011400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265</td>\n",
       "      <td>0.757800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>266</td>\n",
       "      <td>0.278100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>267</td>\n",
       "      <td>0.009300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>268</td>\n",
       "      <td>0.049600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>269</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.002900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>271</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>272</td>\n",
       "      <td>0.393200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>273</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>274</td>\n",
       "      <td>0.001800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.009400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>276</td>\n",
       "      <td>2.594700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>277</td>\n",
       "      <td>0.112600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>278</td>\n",
       "      <td>0.004600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>279</td>\n",
       "      <td>0.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.163700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>281</td>\n",
       "      <td>0.041100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>282</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>283</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285</td>\n",
       "      <td>0.114800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286</td>\n",
       "      <td>0.000800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>287</td>\n",
       "      <td>0.610500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.087000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>289</td>\n",
       "      <td>0.480500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.364100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>291</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>293</td>\n",
       "      <td>0.590400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>294</td>\n",
       "      <td>0.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>0.051500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>0.024900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>297</td>\n",
       "      <td>0.456400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>0.006500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299</td>\n",
       "      <td>1.059000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.300400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>301</td>\n",
       "      <td>0.010900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>302</td>\n",
       "      <td>0.002300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>303</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>304</td>\n",
       "      <td>0.372300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>305</td>\n",
       "      <td>0.027800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>306</td>\n",
       "      <td>0.008300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>307</td>\n",
       "      <td>0.009800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>308</td>\n",
       "      <td>0.005200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>309</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>311</td>\n",
       "      <td>0.782700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>312</td>\n",
       "      <td>0.004400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>313</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>314</td>\n",
       "      <td>0.050700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>315</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>316</td>\n",
       "      <td>0.118500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>317</td>\n",
       "      <td>0.217100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>318</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>319</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>321</td>\n",
       "      <td>0.065200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>322</td>\n",
       "      <td>0.003600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>323</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>324</td>\n",
       "      <td>0.008800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>326</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>327</td>\n",
       "      <td>0.042600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>328</td>\n",
       "      <td>2.057100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>329</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>331</td>\n",
       "      <td>0.024600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>332</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>333</td>\n",
       "      <td>0.940700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>334</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>335</td>\n",
       "      <td>0.002100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>336</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>337</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>338</td>\n",
       "      <td>0.610800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.001800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>341</td>\n",
       "      <td>0.003900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>342</td>\n",
       "      <td>0.235900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>343</td>\n",
       "      <td>0.025700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>344</td>\n",
       "      <td>0.030200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>345</td>\n",
       "      <td>0.672700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>346</td>\n",
       "      <td>0.000800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>347</td>\n",
       "      <td>0.233800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>348</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>349</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.044500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>351</td>\n",
       "      <td>0.014500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.000700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>353</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>354</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>355</td>\n",
       "      <td>0.024400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>356</td>\n",
       "      <td>0.004900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>357</td>\n",
       "      <td>0.017800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>358</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>359</td>\n",
       "      <td>0.505000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>361</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>362</td>\n",
       "      <td>0.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>363</td>\n",
       "      <td>0.013800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>364</td>\n",
       "      <td>0.370900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>365</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>366</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>367</td>\n",
       "      <td>0.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>368</td>\n",
       "      <td>0.000800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>369</td>\n",
       "      <td>0.088600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.002800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>371</td>\n",
       "      <td>0.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>372</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>373</td>\n",
       "      <td>0.038900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>374</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.000800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>376</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>377</td>\n",
       "      <td>0.583400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>378</td>\n",
       "      <td>0.001100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>379</td>\n",
       "      <td>0.053900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>381</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>382</td>\n",
       "      <td>0.020700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>383</td>\n",
       "      <td>0.155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>385</td>\n",
       "      <td>1.267200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>386</td>\n",
       "      <td>0.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>387</td>\n",
       "      <td>0.002100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>388</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>389</td>\n",
       "      <td>0.013200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.007700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>391</td>\n",
       "      <td>0.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>392</td>\n",
       "      <td>1.419000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>393</td>\n",
       "      <td>0.003900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>394</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>0.421700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>0.005800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>401</td>\n",
       "      <td>0.075800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>402</td>\n",
       "      <td>0.023700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>403</td>\n",
       "      <td>0.449700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>404</td>\n",
       "      <td>0.064600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>405</td>\n",
       "      <td>0.072300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>406</td>\n",
       "      <td>0.013600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>407</td>\n",
       "      <td>0.197600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>408</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>409</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411</td>\n",
       "      <td>0.107400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>412</td>\n",
       "      <td>0.004900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>413</td>\n",
       "      <td>0.013100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>414</td>\n",
       "      <td>0.109300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>415</td>\n",
       "      <td>0.142200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>417</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>418</td>\n",
       "      <td>0.249900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>419</td>\n",
       "      <td>0.173900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.016500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>421</td>\n",
       "      <td>0.429900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>422</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>423</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>424</td>\n",
       "      <td>0.406500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.055800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>426</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>427</td>\n",
       "      <td>0.266800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>428</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>429</td>\n",
       "      <td>0.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>431</td>\n",
       "      <td>0.010900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>432</td>\n",
       "      <td>0.183800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>433</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>434</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>435</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>436</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>437</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>438</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>439</td>\n",
       "      <td>0.002100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>441</td>\n",
       "      <td>0.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>442</td>\n",
       "      <td>0.006900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>443</td>\n",
       "      <td>0.010600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>444</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>445</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>446</td>\n",
       "      <td>0.001100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>447</td>\n",
       "      <td>1.461500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>449</td>\n",
       "      <td>0.714100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>451</td>\n",
       "      <td>0.002400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>452</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>453</td>\n",
       "      <td>0.477200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>454</td>\n",
       "      <td>0.056000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>455</td>\n",
       "      <td>0.036400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>456</td>\n",
       "      <td>0.140100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>457</td>\n",
       "      <td>0.312700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>458</td>\n",
       "      <td>0.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>459</td>\n",
       "      <td>0.087400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.003300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>461</td>\n",
       "      <td>0.132300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>462</td>\n",
       "      <td>0.018800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>463</td>\n",
       "      <td>0.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>464</td>\n",
       "      <td>0.033800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>465</td>\n",
       "      <td>0.004200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>466</td>\n",
       "      <td>0.001300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>467</td>\n",
       "      <td>0.039600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>468</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>469</td>\n",
       "      <td>0.029000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>471</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>472</td>\n",
       "      <td>0.081700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>473</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>474</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.024700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>476</td>\n",
       "      <td>0.043500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>477</td>\n",
       "      <td>0.122000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>478</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>479</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>481</td>\n",
       "      <td>0.951600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>482</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>483</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>484</td>\n",
       "      <td>0.267300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>485</td>\n",
       "      <td>1.300600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>486</td>\n",
       "      <td>0.013400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>487</td>\n",
       "      <td>0.029700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>488</td>\n",
       "      <td>0.000800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>489</td>\n",
       "      <td>0.344100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=489, training_loss=0.17422196636990236, metrics={'train_runtime': 1839.3992, 'train_samples_per_second': 1.062, 'train_steps_per_second': 0.266, 'total_flos': 0.0, 'train_loss': 0.17422196636990236, 'epoch': 1.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LoRA configuration - targeting the correct modules for Qwen2.5\n",
    "peft_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\",\"down_proj\"],\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ") # fill the gap\n",
    "\n",
    "# Apply LoRA to the model\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# Training configuration\n",
    "training_args = DPOConfig(\n",
    "    beta=0.1,  # DPO temperature parameter\n",
    "    learning_rate=5e-6,\n",
    "    max_prompt_length=MAX_PROMPT_LEN,\n",
    "    max_length=MAX_LENGTH,\n",
    "    per_device_train_batch_size=1,  # Reduced for memory\n",
    "    gradient_accumulation_steps=4,  # Increased to maintain effective batch size of 4 (1*4)\n",
    "    num_train_epochs=1,\n",
    "    max_grad_norm=1.0,\n",
    "    logging_steps=1,\n",
    "    save_steps=100,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    optim=\"paged_adamw_8bit\",  # More memory efficient\n",
    "    warmup_ratio=0.03, # 3% of the steps will be just a warmup\n",
    "    save_strategy=\"steps\",\n",
    "    output_dir=\"./dpo_model\",\n",
    "    report_to=\"wandb\",\n",
    "    run_name=RUN_NAME,\n",
    "    remove_unused_columns=False,\n",
    "    dataloader_pin_memory=False,\n",
    "    fp16=True,  # Enable mixed precision\n",
    ")\n",
    "\n",
    "# Initialize the trainer - Note: no ref_model needed when using peft_config\n",
    "trainer = DPOTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    peft_config=peft_config,  # This automatically handles reference model\n",
    "    processing_class=tokenizer,\n",
    "    train_dataset=dpo_dataset,\n",
    ")\n",
    "\n",
    "# Print a sample to verify preprocessing\n",
    "print(\"Sample from dataset:\")\n",
    "print(f\"Prompt: {dpo_dataset[0]['prompt']}\")\n",
    "print(f\"Chosen: {dpo_dataset[0]['chosen']}\")\n",
    "print(f\"Rejected: {dpo_dataset[0]['rejected']}\")\n",
    "\n",
    "# Train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mm3zJDWVtUeW",
    "outputId": "31294693-e375-453a-d8e3-0004795e658d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/peft/tuners/lora/bnb.py:348: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('dpo_model/final_merged_dpo_model/tokenizer_config.json',\n",
       " 'dpo_model/final_merged_dpo_model/special_tokens_map.json',\n",
       " 'dpo_model/final_merged_dpo_model/chat_template.jinja',\n",
       " 'dpo_model/final_merged_dpo_model/vocab.json',\n",
       " 'dpo_model/final_merged_dpo_model/merges.txt',\n",
       " 'dpo_model/final_merged_dpo_model/added_tokens.json',\n",
       " 'dpo_model/final_merged_dpo_model/tokenizer.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge LoRA adapters with the base model\n",
    "save_path = \"dpo_model/final_merged_dpo_model\"\n",
    "\n",
    "model = model.merge_and_unload()\n",
    "model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FkbrN3GltUeW"
   },
   "source": [
    "## Model Testing\n",
    "\n",
    "We will test the DPO model via chat-app\n",
    "To validate alignment gains, we‚Äôll spin up a small **Gradio** app that queries both the **pre-DPO** model (baseline/reference) and the **post-DPO** **policy** side-by-side. The UI lets you enter a French prompt, then compares generations using the **same chat template** and decoding settings. This helps spot qualitative shifts in helpfulness, safety, and instruction-following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 802
    },
    "id": "JKtCZEoxtUeW",
    "outputId": "e89f7437-b3f9-44b8-a5f7-2161c8d07161"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading DPO Model from: dpo_model/final_merged_dpo_model\n",
      "‚úÖ DPO Model loaded successfully!\n",
      "üîÑ Loading Base Model from: Qwen/Qwen2.5-0.5B-Instruct\n",
      "‚úÖ Base Model loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/RLHF/chat_app.py:174: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot_dpo_ui = gr.Chatbot(\n",
      "/content/RLHF/chat_app.py:190: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot_base_ui = gr.Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Launching Dual-Model Gradio Chat Interface‚Ä¶\n",
      "üü¢ Finetuned model: dpo_model/final_merged_dpo_model\n",
      "üîµ Base model: Qwen/Qwen2.5-0.5B-Instruct\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://ad44ca8f12db55677c.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://ad44ca8f12db55677c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from RLHF.chat_app import launch_chat_app\n",
    "\n",
    "launch_chat_app(\n",
    "    model_path=save_path, #\"habdine/CSC_53432_lab3_dpo\",\n",
    "    base_model_path=\"Qwen/Qwen2.5-0.5B-Instruct\",\n",
    "    title=\"ü§ñ Dual-Model Qwen Chat (DPO vs Base) for French\",\n",
    "    DPO_TEST=True,\n",
    "    FRENCH_TEST=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "23d0d37599a8487cb63e73e15f9ebd15",
      "0e09730ece524af9aeb9f12b8bede7ca",
      "79bd3083a94b42d08a81cead50273b78",
      "2705eb617ff943ca9fc4aa20d127450c",
      "583f142942424f179b0884ff1a839de8",
      "e097b1b5b3414f5786c2fbe126d68f64",
      "4790491af0474942ae9f8bb57a6461b0",
      "7e70b02fe6ee49cc9428ebf7ebaa6616",
      "91bae5f6a877417c95573aece432a648",
      "d7caeac95324487d84ec54a485b885ef",
      "3ac0443760c740f5b2ca7b182ad1872b",
      "bbf00c73872a4978abe6072c70242e35",
      "9fef08146b07442dab7cdf48a282b86a",
      "6edbc070099d49aba90a97e291504763",
      "d1534d565bd147769d4bcd605409a6a0",
      "b83bacd7bf7b44afb2608ee63ca85503",
      "e55cdc65a5f1482ea9c3fc14a666759b",
      "f41979bb81e24b029f634a903274ff92",
      "c075f1705b68409bb83a6b1a4ab31976",
      "83a4af3036f345aea9354ede09a7db14",
      "f8c179a51d7d4c7ea76a9c1547bca56e",
      "b966438a39c94e28825bff1a7a69f784",
      "9caf5450aa1e4be786a137d93aa47ee1",
      "545d8f0aed7148d0bcbdc6cc7b76cec0",
      "810e2af357d24c0c961052a182ee46be",
      "336699c066c24c3aa5bc29115ce371ae",
      "9c51fea544164b6ba23236b15a788abf",
      "85510ff45c0642fe90222eef7ec5f2cc",
      "41a058fec6d64ff480e2ecb4b0d815c8",
      "464d9f5c376e442fa79ee1f85e0c7c48",
      "7111b6449fe948839f07380a4fef65a4",
      "e0fd675025ec4177afff2c6b005168fd",
      "f8d3fadb4b264fb3aad9fc8cb36ce1f2",
      "1847a915008944c7a5d92c684b7f0342",
      "641e185eadba45f7b86a06c4c6c396d9",
      "ce737ed455ca43548a51d62de770ae27",
      "57c70c8cd5024e27bc845ccc8703805f",
      "97f6ba9eb65747a79016d30e801753e0",
      "c55abd73f24143d6b94fef2193db9c54",
      "7f7ab7ba77d045468a41e8b99260d4ea",
      "d4e9781789134e648858e71a4d3d0283",
      "90af4f63efd7417cabc1704c3fafd46a",
      "cd7476e2cc704c8abba91becbfdd8309",
      "785f1f8f215e4616ad056e5c73a7b4ab",
      "f7470321955240bb8ab181ac9f5a1759",
      "87039170247e472a9147210c4ef371c0",
      "4f2550133c7e4cfa978a9a2c26d57289",
      "d3ef00aa44634cccaaf03e17c94ecc6e",
      "9ccf26102abe4d3dbf9faceb16137e5d",
      "ec921323615a48c5a73ba26ac618bfc4",
      "0e0f2c7c9fe74316afaf8790cc2b8f80",
      "550bb87b48be417ab2a6ebb732e52533",
      "bb6d16722b7a44dba24d23625915aaff",
      "0a7c2e7d911549ecbdecda7d1213c4cd",
      "239fa54ec85e4fdf8c0d481135eee42a",
      "a7a17a87b73b49d399b4cbd18ed43ce0",
      "8bdd030bc67d4476bfe6257f1ed007ee",
      "0de4895bc986498bb9eb282dabc8f5c6",
      "1f36292f73de4fa6b9f16c6357688aca",
      "19518b8d8d3c4fc48cb0f8e96ffef5ee",
      "cac92d9891a8404d8c5e3587efdc2fab",
      "627779580ca94529b62d29b9e690f07c",
      "5d921b81871e45d9af1b7c10e274005b",
      "1634cff784794e62a6b06cca1ca48c14",
      "2253a8ac4fa74a95b8e8d09cb0701999",
      "e015b37234b94809b6dd7f7c3a645b9f",
      "411950f0d5bb47599a989958aaa562bb",
      "2f65500aa1dc48a7b476d6d3c74f4170",
      "d657acb428bb40279ba050d4dd2ad7c1",
      "1931f3ccbde04bb2a4e02583670f6783",
      "44cfb13d1d8549a2bb63851dcb154fc8",
      "3bc5b222005f449d8a27cef6058c2ddb",
      "47fa6273bf4a4da696df3ddd3c1b6062",
      "dc84924001dd40109e06480c7d3e6687",
      "e3e6687913fd4016a0d473e08b74bce0",
      "c1b887a053ab4280a1cfa55f4bc86fdb",
      "f2a42d2bbae647fabdd419e42aa16812",
      "b332afb5acc44635818ecc265e277ead",
      "46cf42fc88df43f490046a1915282df9",
      "b587ba88d7ba42e59a9668696e2ccbf7",
      "8fa8923ecbb044499d461c3172b5e56f",
      "c3795a492e904b4ea4a9c1596b25da97",
      "625efb01a548421abfbc51a853ccf0a6",
      "fa50f9dd1cfc4523b5513ca448b6da67",
      "d2e6df8f4ffb437085d3ca3be441eb17",
      "ad4b3f3a20b04bdd8fcb3bb2b2a099b9",
      "0aba242493414d6e82e4bdba6c99c893",
      "20b40b36bb814b1e8d999251cca8a61c",
      "f198cadcc3694c61974ca603825f353c",
      "484b24b2c06b4b69b501fd1681126af2",
      "d95cf6d5965e4060bb06161941dbd3b8",
      "861095d847ef479d8af664f322e92af0",
      "f76a517ebf4043f38141285634f699c0",
      "a1ece26b67014d958b633a715860d490",
      "53090b315da74844b40b2ba56ceb2ae2",
      "20d208e31bec4e10938eff2bc865c887",
      "cbda87e342624976bbe2f5b18e2fa4c8",
      "a3ee5d896e6d4648aeef347cfa42c793",
      "3359e32cad32466290fa44e058d98c36",
      "8cce1964e25648a8970040c27f411b2f",
      "72f51b474ea542a1b376b51114178e24",
      "2e211733a52442c583b8a5fc467e1bcc",
      "6fae8ab949bc43dea066a0526396504f",
      "b3fab597863443e283fca89b0368abf8",
      "af81b61fb84d4a1fb3607aeff658078e",
      "bae753b8c56a48c4832672dfddbfa79c",
      "4b030a8068ea427883f586a7b3702f43",
      "bf597f534b7d48719345d7bd4f3c18f8",
      "727ec3d7f1974cc2b40f412614d2069a",
      "67dfa17a35294c74ab360efbf5eae7ab"
     ]
    },
    "id": "zvmpsUrOtUeX",
    "outputId": "78dc3ea5-55f5-4618-91a8-c2c3c1e36e98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading DPO Model from: BounharAbdelaziz/Qwen2.5-0.5B-DPO-English-Orca\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d0d37599a8487cb63e73e15f9ebd15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/683 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbf00c73872a4978abe6072c70242e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9caf5450aa1e4be786a137d93aa47ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1847a915008944c7a5d92c684b7f0342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7470321955240bb8ab181ac9f5a1759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7a17a87b73b49d399b4cbd18ed43ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "411950f0d5bb47599a989958aaa562bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b332afb5acc44635818ecc265e277ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/605 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f198cadcc3694c61974ca603825f353c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/613 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cce1964e25648a8970040c27f411b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ DPO Model loaded successfully!\n",
      "üîÑ Loading Base Model from: Qwen/Qwen2.5-0.5B-Instruct\n",
      "‚úÖ Base Model loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/RLHF/chat_app.py:174: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot_dpo_ui = gr.Chatbot(\n",
      "/content/RLHF/chat_app.py:190: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot_base_ui = gr.Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Launching Dual-Model Gradio Chat Interface‚Ä¶\n",
      "üü¢ Finetuned model: BounharAbdelaziz/Qwen2.5-0.5B-DPO-English-Orca\n",
      "üîµ Base model: Qwen/Qwen2.5-0.5B-Instruct\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://19a0fc71f3938665b0.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://19a0fc71f3938665b0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from RLHF.chat_app import launch_chat_app\n",
    "\n",
    "launch_chat_app(\n",
    "    model_path=\"BounharAbdelaziz/Qwen2.5-0.5B-DPO-English-Orca\",\n",
    "    base_model_path=\"Qwen/Qwen2.5-0.5B-Instruct\",\n",
    "    title=\"ü§ñ Dual-Model Qwen Chat (DPO vs Base) for English\",\n",
    "    DPO_TEST=True,\n",
    "    FRENCH_TEST=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jb2KC8TJtUeX"
   },
   "source": [
    "# Part II: GRPO\n",
    "\n",
    "\n",
    "The following diagram illustrates the **GRPO (Generative Reinforcement Preference Optimization)** process ‚Äî an alternative to DPO that directly optimizes generation quality from preference data using reinforcement-style updates:\n",
    "\n",
    "![GRPO Training Overview](https://1drv.ms/i/c/ae69638675180117/IQQ-KizPdUxCRZU9qDGcpX1AAeettH1uhsJqqM1WjXiYR6s?width=705&height=66)\n",
    "\n",
    "After exploring DPO, we now move on to **GRPO** ‚Äî a reinforcement learning‚Äìstyle approach that builds directly on preference data.  \n",
    "While **DPO** adjusts the model using an *analytic loss* derived from preference pairs, **GRPO** takes a more dynamic route: it uses **reward modeling and policy gradients** to optimize the model through sampled generations.\n",
    "\n",
    "In essence:\n",
    "- GRPO **learns from human (or model) preferences** using *on-policy* updates.  \n",
    "- It combines elements of **PPO** (Proximal Policy Optimization) with **preference-based rewards** rather than explicit numerical scores.  \n",
    "- This allows the model to better capture *generation quality* aspects that aren‚Äôt directly expressible through static loss terms.\n",
    "\n",
    "In the next section, we‚Äôll explore how to configure and launch a **GRPO training loop** using `trl`, reusing much of our previous setup (tokenizer, LoRA, quantization) but switching to **on-policy optimization**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "U9K2jcjn12YY"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    TaskType,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "from trl import (\n",
    "    GRPOConfig,\n",
    "    GRPOTrainer,\n",
    ")\n",
    "import os\n",
    "import wandb\n",
    "\n",
    "# We will use wandb.ai for logging the experiments - Set your API key here\n",
    "WANDB_API_KEY = \"6aca9238b1af5d7d1fa6816d9d3c58be843a42e3\" # fill the gap with your wandb key\n",
    "\n",
    "# Automatically login using the API key\n",
    "os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY\n",
    "os.environ[\"WANDB_PROJECT\"] = \"RLHF\"\n",
    "wandb.login()\n",
    "\n",
    "# Training dataset\n",
    "DATASET_PATH = \"openai/gsm8k\"\n",
    "\n",
    "# We limit to 200 samples for speed\n",
    "LIMIT = 200\n",
    "\n",
    "# SFT Model we will finetune\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "# MODEL_NAME = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "# Seed for reproducibility\n",
    "SEED = 1998\n",
    "\n",
    "USE_LORA = True\n",
    "\n",
    "if MODEL_NAME == \"Qwen/Qwen2.5-0.5B-Instruct\":\n",
    "  USE_QUANT = False\n",
    "else:\n",
    "  USE_QUANT = True\n",
    "\n",
    "lora_alpha = 128\n",
    "lora_r = 64\n",
    "lora_dropout = 0.1\n",
    "\n",
    "if not USE_LORA:\n",
    "  MAX_PROMPT_LEN = 512\n",
    "  MAX_LENGTH = MAX_PROMPT_LEN + 512\n",
    "else:\n",
    "    MAX_PROMPT_LEN = 150\n",
    "    MAX_LENGTH = MAX_PROMPT_LEN + 150\n",
    "\n",
    "RUN_NAME = \"GRPO-GSM8K-limit-\" + str(LIMIT) + \"-\" + MODEL_NAME.split('/')[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2fRTvtVGtUeX"
   },
   "source": [
    "## Load the SFT Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4UkT_7Y_tUeX",
    "outputId": "0acf283b-e618-4651-8204-21d8880ab225"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 35,192,832 || all params: 529,225,600 || trainable%: 6.6499\n"
     ]
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Quantization configuration\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# Load the model to finetune\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float16,\n",
    "    quantization_config=quantization_config if USE_QUANT else None,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# Prepare model for k-bit training\n",
    "if USE_QUANT:\n",
    "  model = prepare_model_for_kbit_training(model)\n",
    "model.config.use_cache = False\n",
    "\n",
    "# Add padding token if not exists\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "if USE_LORA:\n",
    "\n",
    "  # Configure LoRA\n",
    "  lora_config = LoraConfig(\n",
    "      r=lora_r,  # Rank of adaptation\n",
    "      lora_alpha=lora_alpha,  # LoRA scaling parameter\n",
    "      target_modules=[\n",
    "          \"q_proj\",\n",
    "          \"k_proj\",\n",
    "          \"v_proj\",\n",
    "          \"o_proj\",\n",
    "          \"gate_proj\",\n",
    "          \"up_proj\",\n",
    "          \"down_proj\",\n",
    "      ],  # Target modules for Qwen2.5 architecture\n",
    "      lora_dropout=lora_dropout,  # LoRA dropout\n",
    "      bias=\"none\",  # Bias type\n",
    "      task_type=TaskType.CAUSAL_LM,  # Task type\n",
    "  )\n",
    "\n",
    "  # Apply LoRA to the model\n",
    "  model = get_peft_model(model, lora_config)\n",
    "\n",
    "  # Print trainable parameters\n",
    "  model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jo1slG9tUeX"
   },
   "source": [
    "## Data Preparation\n",
    "\n",
    "For GRPO training, we‚Äôll use the **GSM8K** dataset ‚Äî a benchmark of grade-school math word problems.  \n",
    "Each problem includes a **question** and a **final answer**. Our goal is to teach the model to reason in French (or English if you prefer) and **output only the final numeric answer** enclosed between `<answer>` and `</answer>` tags.\n",
    "\n",
    "This format makes automatic evaluation trivial ‚Äî we can extract the number between tags and compare it directly to the reference.\n",
    "\n",
    "With GRPO the model will learn two main things:\n",
    "- How follow the instruction to output the correct format.\n",
    "- Gain more math capabilities\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Why structure as chat messages?\n",
    "\n",
    "Just like with DPO, the **Qwen2.5-0.5B-Instruct** model expects inputs in a *chat-style message format*.  \n",
    "We‚Äôll use:\n",
    "- A **system message** to define the task and output style.\n",
    "- A **user message** with the math problem.\n",
    "- An **assistant message** containing the reasoning and final numeric answer wrapped in tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DQ-3KLwb242"
   },
   "source": [
    "<b><h4><font color='blue'>\n",
    "<hr style=\"border:10px solid blue\"> </hr>\n",
    "Task 5: </b><br>\n",
    "Create your training samples as following:<br>\n",
    "1- system message: R1_STYLE_SYSTEM_PROMPT + \"\\n\" + TASK_SPECIFIC_INSTRUCTIONS <br>\n",
    "2- one-shot example of user message of \"What is 2+2?\" and an assistant message of \"To calculate 2+2, we simply add the numbers together: 2 + 2 = 4.\\n$<answer>$4$</answer>$\" <br>\n",
    "3- the question sample from the dataset as a user message.\n",
    "<hr style=\"border:10px solid blue\"> </hr>\n",
    "</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209,
     "referenced_widgets": [
      "bf0137145c0f494cbff84392a593ed23",
      "76ded5aefd25446f9a8828ec5cb10b91",
      "26d7cb0216ac423b87a29c754249793c",
      "a0f1edc28ded4edcbe5fcee5bbe46227",
      "810da688849d4268b316df9463737aef",
      "29c553f0b4c44dc3b5bbf9fd50d288cc",
      "e2c7565acf2d45db82b7527d950447dc",
      "6c9cf9637b8b4018b8c04b4374c6c87d",
      "c491122c946d41bbbd4c80d8611beeaf",
      "ee5abd63f24848a4b3c532bca08dd07f",
      "2ba8e1aee669437ba008b39168d3a236",
      "7d912e8ae5e34547b33fbccf2425584b",
      "5f850e80ae004620b10edf6bb9a518be",
      "4b0eedf36de343288295703a0dd08e6e",
      "750eaecdb25149d39c1182afcd1d9256",
      "b467994993774308aeda0df233a0f356",
      "1cfcb59f952e4b50a0c57071a094f27e",
      "4d41d6638f774c9d812b4d76e2334651",
      "73db2d96fb7549ebb6e78ed22abd0d2e",
      "2f852ce860a04ff7a17ee2a6a358cecf",
      "509e8044836049f68299581e28c5178d",
      "80806eac002845b1b5d5b316a1b210ae",
      "3d0a3bf9f2cf48e1884dbc3e45f7a040",
      "47b6313c3d214d908d09ad76ade7735b",
      "7028643fc00446cbb66ddaed341a75eb",
      "39ba7cbc762d4b819ccddad801332932",
      "e5a08daf5b5b4d21866cebedd3369405",
      "6ab0da8346d548609def71e1aee686a3",
      "b28cfa4ff9af426796e0ce4e3b39336e",
      "a892c0f47e2a43839b1055748a02982b",
      "01709027cce64ec6af94696b8008c689",
      "6f901db5653e47e6b62d17121bf6539c",
      "3349973238cc4bd788ef460e1b884f0b",
      "fa729cfe2f7244138c0c7feb33107c3d",
      "892dbe21c156428989eadf794b051211",
      "0593400854284baeb038f3e9ee68ec3d",
      "4439e984883748c09e0db6ac7fa5701a",
      "fbef248416fc46ae9a3179bbac13a0cb",
      "1ba1314c6c674c1185bdf4e0a129db77",
      "6a193dbde34f4ccd849dd5a6c87af8c8",
      "46476b0b06f5491ea782f20b6388701f",
      "dc919421f4d0446c983110863ab00de8",
      "07575362a6a1447aa5c45bbeb7c0c4e4",
      "ef1c5c912b2541359686d83d936e016d",
      "abf3f003de4348999a96121f9a0a7f43",
      "c23e7e28b1e4498494de0e13f7c2aa39",
      "3198a8e405b144b296554e73196cf4f9",
      "3675727e5bc24c2a84dea191d01e5ce4",
      "8e38c1188548477faa1cd257193743ae",
      "aa92e6d84c914e9eb6868773221fd100",
      "ae226c6fb1f74c6f95ca3cd43354f2b0",
      "3ee14dda7e05435982ddbbed4e832059",
      "d1b5b310bf7b4665a727478bb9c92504",
      "1b6f3b0967e3441a941845535a09502b",
      "1704c92c79c94115934727b9e5721ff9",
      "b0b72a2e8e0e4f45ab0abc6464b19797",
      "c3290a8b00b94d398278a88549e55d39",
      "84dd1768f509447784bc59b6fdc11816",
      "9a9dafeca58a4ae5a1a9c753ddcf2c47",
      "18ae5696e03f4369b857057be0504bd2",
      "b52403046ae646f8b6959b0b3104df7a",
      "36360c3b38e5472084e9ce18d1ed3125",
      "0ad1c847e1124933ba266c04c6c22a4c",
      "147904bb7ff24b0d9963a7d3603705c8",
      "2ade665c214546cc80699dbaaeedd139",
      "6f4be00a5c0848c9ab872cf720c6de25"
     ]
    },
    "id": "U95rr5j-tUeX",
    "outputId": "184fdf3f-3e70-4b51-e9a7-1f55829b70d2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0137145c0f494cbff84392a593ed23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d912e8ae5e34547b33fbccf2425584b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "main/train-00000-of-00001.parquet:   0%|          | 0.00/2.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d0a3bf9f2cf48e1884dbc3e45f7a040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "main/test-00000-of-00001.parquet:   0%|          | 0.00/419k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa729cfe2f7244138c0c7feb33107c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf3f003de4348999a96121f9a0a7f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b72a2e8e0e4f45ab0abc6464b19797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load GSM8K dataset\n",
    "if LIMIT:\n",
    "    dataset = load_dataset(DATASET_PATH, \"main\", split=f\"train[:{LIMIT}]\")  # Small subset for demo\n",
    "else:\n",
    "    dataset = load_dataset(DATASET_PATH, \"main\")\n",
    "\n",
    "R1_STYLE_SYSTEM_PROMPT = \"\"\"A conversation between User and Assistant. The user asks a question, and the Assistant solves it.\n",
    "The assistant first thinks shortly about the reasoning process in the mind and then provides the user with the answer in a new line between <answer> and </answer>.\"\"\"\n",
    "\n",
    "TASK_SPECIFIC_INSTRUCTIONS = \"The answer must be a single integer.\"\n",
    "\n",
    "def preprocess_dataset(dataset, chunk_size=1000) -> Dataset:\n",
    "\n",
    "    def extract_hash_answer(text: str) -> str | None:\n",
    "        try:\n",
    "            return text.split(\"####\")[1].strip()\n",
    "        except IndexError:\n",
    "            return None\n",
    "\n",
    "    def process_batch(batch):\n",
    "        prompts = [\n",
    "        R1_STYLE_SYSTEM_PROMPT\n",
    "        + \"\\n\"\n",
    "        + TASK_SPECIFIC_INSTRUCTIONS\n",
    "        + \"\\n\\n\"\n",
    "        + \"User: What is 2+2?\\n\"\n",
    "        + \"Assistant: To calculate 2+2, we simply add the numbers together: 2 + 2 = 4.\\n\"\n",
    "        + \"<answer>4</answer>\\n\\n\"\n",
    "        + f\"User: {question}\"\n",
    "        for question in batch[\"question\"] # fill the gap : create the training samples in the batch\n",
    "        ]\n",
    "\n",
    "        return {\n",
    "            'prompt': prompts,\n",
    "            'answer': [extract_hash_answer(a) for a in batch['answer']]\n",
    "        }\n",
    "\n",
    "    return dataset.map(process_batch, batched=True, batch_size=chunk_size)\n",
    "train_dataset = preprocess_dataset(dataset, chunk_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ra_X_fK-22Ve"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qvwShnXPhJxI",
    "outputId": "9cba38db-3946-416d-a97b-1ae3861ee949"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?',\n",
       " 'answer': '72',\n",
       " 'prompt': 'A conversation between User and Assistant. The user asks a question, and the Assistant solves it.\\nThe assistant first thinks shortly about the reasoning process in the mind and then provides the user with the answer in a new line between <answer> and </answer>.\\nThe answer must be a single integer.\\n\\nUser: What is 2+2?\\nAssistant: To calculate 2+2, we simply add the numbers together: 2 + 2 = 4.\\n<answer>4</answer>\\n\\nUser: Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2AsDSYi3tUeX"
   },
   "source": [
    "## Reward Function Design\n",
    "\n",
    "We‚Äôll use **two simple rewards** during GRPO rollouts:\n",
    "\n",
    "1. **Format reward** ‚Äî checks that the **last non-empty line** is exactly in the form  \n",
    "   `<answer>NUMBER</answer>`  \n",
    "   - Score: **1** if correct format, **0** otherwise.\n",
    "\n",
    "2. **Correctness reward** ‚Äî checks whether the extracted number matches the gold answer.  \n",
    "   - Score: **2** if correct, **0** otherwise.\n",
    "\n",
    "Total reward per sample ‚àà {0, 1, 2, 3}.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0sLEkm7ec9HN"
   },
   "source": [
    "<b><h4><font color='blue'>\n",
    "<hr style=\"border:10px solid blue\"> </hr>\n",
    "Task 6: </b><br>\n",
    "write the `extract_xml_answer` function to extract the answer from the generated text.\n",
    "<hr style=\"border:10px solid blue\"> </hr>\n",
    "</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "GjvdHWcVtUeX"
   },
   "outputs": [],
   "source": [
    "def extract_xml_answer(text: str) -> str:\n",
    "    match = re.search(r\"<answer>\\s*([-+]?\\d+)\\s*</answer>\", text)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    fallback = re.findall(r\"[-+]?\\d+\", text)\n",
    "    if fallback:\n",
    "        return fallback[-1]\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "def format_reward_func(completions, **kwargs) -> list[float]:\n",
    "    \"\"\"Reward function that checks if the completion has the correct format.\"\"\"\n",
    "    pattern = r\"^(?:[^\\r\\n]*\\r?\\n)+<answer>\\d+</answer>\\r?\\n?$\"\n",
    "    responses = completions\n",
    "    matches = [bool(re.match(pattern, r)) for r in responses]\n",
    "    return [1.0 if match else 0.0 for match in matches]\n",
    "\n",
    "def correctness_reward_func(prompts, completions, answer, **kwargs) -> list[float]:\n",
    "    \"\"\"Reward function that checks if the answer is correct.\"\"\"\n",
    "    responses = completions\n",
    "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
    "    return [2.0 if r == a else 0.0 for r, a in zip(extracted_responses, answer)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FoWWcLFhtUeX"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "hAcuDydttUeY",
    "outputId": "68641934-8f18-4a9f-f3ac-16a0d827d7d7"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GRPOConfig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2691619553.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# GRPO Configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m grpo_config = GRPOConfig(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./grpo_model\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mper_device_train_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GRPOConfig' is not defined"
     ]
    }
   ],
   "source": [
    "# GRPO Configuration\n",
    "grpo_config = GRPOConfig(\n",
    "    output_dir=\"./grpo_model\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=1,\n",
    "    num_train_epochs=3,\n",
    "    max_prompt_length=MAX_PROMPT_LEN,\n",
    "    max_completion_length=MAX_LENGTH,\n",
    "    num_generations=2, # The effective train batch size must be evenly divisible by the number of generations per prompt\n",
    "    beta=0,\n",
    "    epsilon=0.28,\n",
    "    temperature=1,\n",
    "    logging_steps=1,\n",
    "    save_steps=25,\n",
    "    save_total_limit=3,\n",
    "    # load_best_model_at_end=True,\n",
    "    # metric_for_best_model=\"reward\",\n",
    "    # greater_is_better=True,\n",
    "    run_name=RUN_NAME,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    optim=\"paged_adamw_8bit\" ,  # More memory efficient\n",
    "    warmup_ratio=0.03, # 3% of the steps will be just a warmup\n",
    "    remove_unused_columns=False,\n",
    "    dataloader_pin_memory=False,\n",
    "    fp16=True,  # Enable mixed precision\n",
    ")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = GRPOTrainer(\n",
    "    model=model,\n",
    "    reward_funcs=[format_reward_func, correctness_reward_func],\n",
    "    args=grpo_config,\n",
    "    train_dataset=train_dataset,\n",
    "    processing_class=tokenizer,\n",
    ")\n",
    "\n",
    "# Training\n",
    "print(\"Starting GRPO training...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "Vt3VtLn0tUeY",
    "outputId": "0ae8531a-543e-460e-ab15-2b3fef5f2f79"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2962433712.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"grpo_model/final_merged_grpo_model\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_and_unload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# merge LoRA adapters with the base model\n",
    "save_path = \"grpo_model/final_merged_grpo_model\"\n",
    "\n",
    "model = model.merge_and_unload()\n",
    "model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWgS802UtUeY"
   },
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 802
    },
    "id": "7ViMeNJ9tUeY",
    "outputId": "b9994535-2489-4fdb-f1ea-c748737af15e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading DPO Model from: grpo_model/final_merged_grpo_model\n",
      "‚úÖ DPO Model loaded successfully!\n",
      "üîÑ Loading Base Model from: Qwen/Qwen2.5-0.5B-Instruct\n",
      "‚úÖ Base Model loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/RLHF/chat_app.py:174: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot_dpo_ui = gr.Chatbot(\n",
      "/content/RLHF/chat_app.py:190: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot_base_ui = gr.Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Launching Dual-Model Gradio Chat Interface‚Ä¶\n",
      "üü¢ Finetuned model: grpo_model/final_merged_grpo_model\n",
      "üîµ Base model: Qwen/Qwen2.5-0.5B-Instruct\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://52aa6029f91b1948e6.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://52aa6029f91b1948e6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from RLHF.chat_app import launch_chat_app\n",
    "\n",
    "launch_chat_app(\n",
    "    model_path=save_path,#\"habdine/CSC_53432_lab3_grpo\"\n",
    "    base_model_path=\"Qwen/Qwen2.5-0.5B-Instruct\",\n",
    "    title=\"ü§ñ Dual-Model Qwen Chat (GRPO vs Base) for Math\",\n",
    "    DPO_TEST=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qIpnugPkeStI"
   },
   "source": [
    "## üìà Model Evaluation\n",
    "\n",
    "Once our GRPO-trained model is ready, we need to **evaluate its performance**  ‚Äî to verify that it has learned to produce correctly formatted and accurate answers.\n",
    "\n",
    "For computational issues, we will evaluate on the first 200 samples only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tEE-nS0I33TW",
    "outputId": "eddf3d1b-0ff6-4ec6-a8dd-4c4402b5cb0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GSM8K evaluation...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "import json\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "\n",
    "def extract_hash_answer(text: str) -> str | None:\n",
    "    try:\n",
    "        return text.split(\"####\")[1].strip()\n",
    "    except IndexError:\n",
    "        return None\n",
    "\n",
    "def extract_xml_answer(text: str) -> str:\n",
    "    # Make the regex more robust to whitespace and potential extra characters\n",
    "    answer_match = re.search(r\"<answer>\\s*(.*?)\\s*</answer>\", text, re.DOTALL)\n",
    "    return answer_match.group(1).strip() if answer_match else \"\"\n",
    "\n",
    "def evaluate_model(\n",
    "    model_path: str,\n",
    "    batch_size: int = 1,\n",
    "    num_samples: int = None,\n",
    "    save_results: bool = True,\n",
    ") -> Dict:\n",
    "    print(\"Initializing evaluation...\")\n",
    "\n",
    "    with tqdm(total=2, desc=\"Loading model components\") as pbar:\n",
    "        llm = AutoModelForCausalLM.from_pretrained(\n",
    "            model_path,\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map=\"cuda:0\",\n",
    "            trust_remote_code=True,\n",
    "        )\n",
    "        pbar.update(1)\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\n",
    "            model_path,\n",
    "            model_max_length=768,\n",
    "        )\n",
    "        pbar.update(1)\n",
    "\n",
    "    # Load test dataset\n",
    "    print(\"Loading dataset...\")\n",
    "    dataset = load_dataset('openai/gsm8k', 'main', split='test')\n",
    "    if num_samples:\n",
    "        dataset = dataset.select(range(num_samples))\n",
    "    total_samples = len(dataset)\n",
    "    print(f\"Loaded {total_samples} samples\")\n",
    "\n",
    "    results = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Create progress bar\n",
    "    progress_bar = tqdm(\n",
    "        total=total_samples,\n",
    "        desc=\"Processing samples\",\n",
    "        unit=\"examples\",\n",
    "        dynamic_ncols=True,\n",
    "    )\n",
    "\n",
    "    progress_bar.set_postfix({\n",
    "        'acc': '0.00%',\n",
    "        'correct': '0',\n",
    "    })\n",
    "\n",
    "    # Process in batches\n",
    "    for i in range(0, total_samples, batch_size):\n",
    "        batch_data = dataset[i:i + batch_size]\n",
    "        current_batch_size = len(batch_data['question'])\n",
    "\n",
    "        # Prepare prompts using same format as training\n",
    "        prompts = [\n",
    "            [\n",
    "                {'role': 'system', 'content': R1_STYLE_SYSTEM_PROMPT + \"\\n\" + TASK_SPECIFIC_INSTRUCTIONS},\n",
    "                {'role': 'user', 'content': \"What is 2+2?\"},\n",
    "                {'role': 'assistant', 'content': \"To calculate 2+2, we simply add the numbers together: 2 + 2 = 4.\\n<answer>4</answer>\"},\n",
    "                {'role': 'user', 'content': q.strip()}\n",
    "            ] for q in batch_data['question']\n",
    "        ]\n",
    "\n",
    "        # Convert to chat format\n",
    "        formatted_prompts = [\n",
    "            tokenizer.apply_chat_template(\n",
    "                p,\n",
    "                tokenize=True,\n",
    "                return_tensors='pt',\n",
    "                add_generation_prompt=True\n",
    "            )\n",
    "            for p in prompts\n",
    "        ]\n",
    "\n",
    "        # Generate responses\n",
    "        outputs = []\n",
    "        for prompt in formatted_prompts:\n",
    "            output = llm.generate(\n",
    "                prompt.to('cuda:0'),\n",
    "                max_new_tokens=512,\n",
    "                temperature=1.0,\n",
    "            )\n",
    "            outputs.append(output)\n",
    "\n",
    "\n",
    "        # Process responses\n",
    "        for j, output in enumerate(outputs):\n",
    "\n",
    "            response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "            # Extract answers\n",
    "            generated_answer = extract_xml_answer(response)\n",
    "            true_answer = extract_hash_answer(batch_data['answer'][j])\n",
    "\n",
    "            # Print sample for debugging\n",
    "            if i < 5: # Print first 5 samples\n",
    "                print(f\"\\n--- Sample {i+j+1} ---\")\n",
    "                print(f\"Question: {batch_data['question'][j]}\")\n",
    "                print(f\"Generated Response: {response}\")\n",
    "                print(f\"Extracted Answer: {generated_answer}\")\n",
    "                print(f\"True Answer: {true_answer}\")\n",
    "                print(\"-\" * 20)\n",
    "\n",
    "\n",
    "            # Store result\n",
    "            result = {\n",
    "                'question': batch_data['question'][j],\n",
    "                'true_answer': true_answer,\n",
    "                'generated_answer': generated_answer,\n",
    "                'full_response': response,\n",
    "                'correct': generated_answer == true_answer\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "            # Update metrics\n",
    "            if generated_answer == true_answer:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "        # Update progress\n",
    "        progress_bar.update(current_batch_size)\n",
    "        progress_bar.set_postfix({\n",
    "            'acc': f'{(correct/total)*100:.2f}%',\n",
    "            'correct': f'{correct}/{total}',\n",
    "        })\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'correct': correct,\n",
    "        'total': total,\n",
    "        'model_path': model_path,\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "    # Save results\n",
    "    if save_results:\n",
    "        save_path = f\"gsm8k_eval_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "        with open(save_path, 'w') as f:\n",
    "            json.dump({\n",
    "                'metrics': metrics,\n",
    "                'results': results\n",
    "            }, f, indent=2)\n",
    "        print(f\"\\nResults saved to {save_path}\")\n",
    "\n",
    "    return metrics\n",
    "\n",
    "print(\"Starting GSM8K evaluation...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcED_4Npdms2"
   },
   "source": [
    "<b><h4><font color='blue'>\n",
    "<hr style=\"border:10px solid blue\"> </hr>\n",
    "Task 7: </b><br>\n",
    "evaluate the model before and after GRPO training.\n",
    "<hr style=\"border:10px solid blue\"> </hr>\n",
    "</font></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WqjBrw25ehbd"
   },
   "source": [
    "### Evaluation after GRPO\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "fffd566f855042f19159ef3afc04fbfa",
      "69c7f6d8a8e947a1b729f60452318482",
      "cf395bca149e40508df14b76a4d9e748",
      "90fba52685f846998b6b358238eb0552",
      "b705ad2a1ba5444cba8b12dea9640f35",
      "51411690728e40b28eca2843f2d9b0fb",
      "1b8c1b2a43b44da5a1c597c2604c0db3",
      "f6e50ee5df4b499397c0b7ce44022b1e",
      "8fe562ae3d1a4c10b920fe59213813f5",
      "ae3a80021d4742539bae5f4ba4806d17",
      "a84850a2280d462d8c9c5bacc9fcdff9",
      "1c6065a138fc46fa9fa92671c2238a50",
      "1c70b4e22d6d49159acecfbf814f08a3",
      "8a7ae6a9ef594379a2b52fc9d0913222",
      "8e690b31ecb347fcb57c3d4692037159",
      "0d53218df26749c78461554976bf9c99",
      "221f6822827c4ff3b1dd2e4aecdb4132",
      "4f1cff6c36e0447680a229a46a5631e5",
      "d1b4579469f941e085042650d50b25cb",
      "a09561b16e0b40ff93e004f6ae6ae4c1",
      "0dc843f6b9364cd193fecfc8562d0495",
      "e85d077bd05a404e980e4922aa4c7a0b"
     ]
    },
    "id": "rVBttE_aei4B",
    "outputId": "5b4e56e9-a2af-40c2-8927-b6f7c84c8180"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing evaluation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fffd566f855042f19159ef3afc04fbfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading model components:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Loaded 200 samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c6065a138fc46fa9fa92671c2238a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing samples:   0%|          | 0/200 [00:00<?, ?examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sample 1 ---\n",
      "Question: Janet‚Äôs ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\n",
      "Generated Response: system\n",
      "A conversation between User and Assistant. The user asks a question, and the Assistant solves it.\n",
      "The assistant first thinks shortly about the reasoning process in the mind and then provides the user with the answer in a new line between <answer> and </answer>.\n",
      "The answer must be a single integer.\n",
      "user\n",
      "What is 2+2?\n",
      "assistant\n",
      "To calculate 2+2, we simply add the numbers together: 2 + 2 = 4.\n",
      "<answer>4</answer>\n",
      "user\n",
      "Janet‚Äôs ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\n",
      "assistant\n",
      "First, let's determine how many eggs Janet has after her breakfast and baking:\n",
      "\n",
      "- Breakfast: 3 eggs\n",
      "- Baking: 4 eggs\n",
      "\n",
      "So, total eggs before selling are:\n",
      "3 (breakfast) + 4 (baking) = 7 eggs\n",
      "\n",
      "Next, let's find out how many eggs are left for sale when all 7 are sold:\n",
      "\n",
      "Eggs left for sale = Total eggs - Eggs laid per day = 7 - 16 = -9\n",
      "\n",
      "Since the number of eggs left is negative, this means Janet doesn't have any leftover to sell at the market; instead, she runs out of eggs. Therefore, there would be no money made from selling them.\n",
      "Extracted Answer: and\n",
      "True Answer: 18\n",
      "--------------------\n",
      "\n",
      "--- Sample 2 ---\n",
      "Question: A robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolts in total does it take?\n",
      "Generated Response: system\n",
      "A conversation between User and Assistant. The user asks a question, and the Assistant solves it.\n",
      "The assistant first thinks shortly about the reasoning process in the mind and then provides the user with the answer in a new line between <answer> and </answer>.\n",
      "The answer must be a single integer.\n",
      "user\n",
      "What is 2+2?\n",
      "assistant\n",
      "To calculate 2+2, we simply add the numbers together: 2 + 2 = 4.\n",
      "<answer>4</answer>\n",
      "user\n",
      "A robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolts in total does it take?\n",
      "assistant\n",
      "If a robe takes 2 bolts of blue fiber and half as much white fiber (which means 1 bolt), it would also need 1 bolt of white fiber. Therefore, to make one robe, you would need 3 bolts of fiber since 2 blue and 1 white are combined for each outfit.\n",
      "\n",
      "So in total, it would take 3 bolts of fiber to make one robe.\n",
      "Extracted Answer: and\n",
      "True Answer: 3\n",
      "--------------------\n",
      "\n",
      "--- Sample 3 ---\n",
      "Question: Josh decides to try flipping a house.  He buys a house for $80,000 and then puts in $50,000 in repairs.  This increased the value of the house by 150%.  How much profit did he make?\n",
      "Generated Response: system\n",
      "A conversation between User and Assistant. The user asks a question, and the Assistant solves it.\n",
      "The assistant first thinks shortly about the reasoning process in the mind and then provides the user with the answer in a new line between <answer> and </answer>.\n",
      "The answer must be a single integer.\n",
      "user\n",
      "What is 2+2?\n",
      "assistant\n",
      "To calculate 2+2, we simply add the numbers together: 2 + 2 = 4.\n",
      "<answer>4</answer>\n",
      "user\n",
      "Josh decides to try flipping a house.  He buys a house for $80,000 and then puts in $50,000 in repairs.  This increased the value of the house by 150%.  How much profit did he make?\n",
      "assistant\n",
      "First, let's find out the total cost including the initial purchase price and the repairs. We have:\n",
      "\n",
      "1. Cost of the house: $80,000\n",
      "2. Initial repair costs: $50,000\n",
      "\n",
      "So, the total initial cost is:\n",
      "$80,000 (house) + $50,000 (repair costs) = $130,000\n",
      "\n",
      "Next, we need to determine the increase in the house's value due to these repairs. To do this, we multiply the total initial cost by the percentage increase:\n",
      "$130,000 * 150% = $195,000\n",
      "\n",
      "This means that Josh's house's value increased by $195,000.\n",
      "\n",
      "Finally, we subtract the original cost of the house from the increased value to find the profit:\n",
      "Increased value - Original cost = Profit\n",
      "$195,000 - $80,000 = $115,000\n",
      "\n",
      "Therefore, Josh made a profit of $115,000 on flipping his house.\n",
      "Extracted Answer: and\n",
      "True Answer: 70000\n",
      "--------------------\n",
      "\n",
      "--- Sample 4 ---\n",
      "Question: James decides to run 3 sprints 3 times a week.  He runs 60 meters each sprint.  How many total meters does he run a week?\n",
      "Generated Response: system\n",
      "A conversation between User and Assistant. The user asks a question, and the Assistant solves it.\n",
      "The assistant first thinks shortly about the reasoning process in the mind and then provides the user with the answer in a new line between <answer> and </answer>.\n",
      "The answer must be a single integer.\n",
      "user\n",
      "What is 2+2?\n",
      "assistant\n",
      "To calculate 2+2, we simply add the numbers together: 2 + 2 = 4.\n",
      "<answer>4</answer>\n",
      "user\n",
      "James decides to run 3 sprints 3 times a week.  He runs 60 meters each sprint.  How many total meters does he run a week?\n",
      "assistant\n",
      "To determine how many meters James runs in a week, we need to follow these steps:\n",
      "\n",
      "1. **Calculate the distance for one sprint**: \n",
      "   James runs 60 meters in each sprint.\n",
      "\n",
      "2. **Determine the number of sprints per session**:\n",
      "   James runs 3 times a week.\n",
      "\n",
      "3. **Find the total distance for all sessions**:\n",
      "   Multiply the distance of one sprint by the number of sessions per week:\n",
      "   \\[\n",
      "   60 \\text{ meters/sprint} \\times 3 \\text{ sessions/week} = 180 \\text{ meters/week}\n",
      "   \\]\n",
      "\n",
      "Therefore, James runs a total of **180 meters** in a week.\n",
      "Extracted Answer: and\n",
      "True Answer: 540\n",
      "--------------------\n",
      "\n",
      "--- Sample 5 ---\n",
      "Question: Every day, Wendi feeds each of her chickens three cups of mixed chicken feed, containing seeds, mealworms and vegetables to help keep them healthy.  She gives the chickens their feed in three separate meals. In the morning, she gives her flock of chickens 15 cups of feed.  In the afternoon, she gives her chickens another 25 cups of feed.  How many cups of feed does she need to give her chickens in the final meal of the day if the size of Wendi's flock is 20 chickens?\n",
      "Generated Response: system\n",
      "A conversation between User and Assistant. The user asks a question, and the Assistant solves it.\n",
      "The assistant first thinks shortly about the reasoning process in the mind and then provides the user with the answer in a new line between <answer> and </answer>.\n",
      "The answer must be a single integer.\n",
      "user\n",
      "What is 2+2?\n",
      "assistant\n",
      "To calculate 2+2, we simply add the numbers together: 2 + 2 = 4.\n",
      "<answer>4</answer>\n",
      "user\n",
      "Every day, Wendi feeds each of her chickens three cups of mixed chicken feed, containing seeds, mealworms and vegetables to help keep them healthy.  She gives the chickens their feed in three separate meals. In the morning, she gives her flock of chickens 15 cups of feed.  In the afternoon, she gives her chickens another 25 cups of feed.  How many cups of feed does she need to give her chickens in the final meal of the day if the size of Wendi's flock is 20 chickens?\n",
      "assistant\n",
      "Wendi has a total of 20 chickens * 3 cups of feed per chicken = 60 cups of feed for all the chickens combined. In the morning, she gave 15 cups so far, and in the afternoon, she added another 25 cups, bringing the total to 15 + 25 = 40 cups.\n",
      "Since she already had 60 cups of feed by the end of the morning feeding time, this means that she still needs to have 60 - 40 = 20 more cups of feed left for her flock.\n",
      "\n",
      "Therefore, Wendi needs to give her chickens an additional 20 cups of mixed feed to finish up their supplies for the day.</li></ol>\n",
      "<answer>20</answer>\n",
      "Extracted Answer: and\n",
      "True Answer: 20\n",
      "--------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3235033176.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m metrics_after = evaluate_model(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"grpo_model/final_merged_grpo_model\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msave_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-3716998233.py\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model_path, batch_size, num_samples, save_results)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformatted_prompts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             output = llm.generate(\n\u001b[0m\u001b[1;32m    101\u001b[0m                 \u001b[0mprompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2563\u001b[0m         \u001b[0;31m# 9. Call generation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2564\u001b[0;31m         result = decoding_method(\n\u001b[0m\u001b[1;32m   2565\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2566\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2785\u001b[0m                 \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2786\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2787\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2789\u001b[0m             \u001b[0;31m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;34m\"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         ```\"\"\"\n\u001b[0;32m--> 449\u001b[0;31m         outputs: BaseModelOutputWithPast = self.model(\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moriginal_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m             \u001b[0;31m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdecoder_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             hidden_states = decoder_layer(\n\u001b[0m\u001b[1;32m    385\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdecoder_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_checkpointing_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m     ) -> torch.Tensor:\n\u001b[1;32m    231\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0;31m# Self Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         hidden_states, _ = self.self_attn(\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metrics_after = evaluate_model(\n",
    "    model_path=\"grpo_model/final_merged_grpo_model\",\n",
    "    batch_size=1,\n",
    "    num_samples=200,\n",
    "    save_results=True,\n",
    ")\n",
    "print(json.dumps(metrics_after, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9EDtisKR2lp"
   },
   "source": [
    "## Evaluation before GRPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VuRgDWiiRlRb"
   },
   "outputs": [],
   "source": [
    "metrics_before = evaluate_model(\n",
    "    model_path=\"QWen/Qwen2.5-0.5B-Instruct\",\n",
    "    batch_size=1,\n",
    "    num_samples=200,\n",
    "    save_results=True,\n",
    ")\n",
    "print(json.dumps(metrics_before, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rbMm8jM-ZFN7"
   },
   "source": [
    "Note: I changed my GRPO code but had no more T4 Memory so I couldn't test de evaluation of the metrics again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vxM1p70fulX"
   },
   "source": [
    "<b><h4><font color='red'>\n",
    "<hr style=\"border:10px solid red\"> </hr>\n",
    "Question 1: </b><br>\n",
    "\n",
    "- What are the main conceptual and practical differences between **Direct Preference Optimization (DPO)** and **Generative Reinforcement Preference Optimization (GRPO)**?  \n",
    "- In what situations might one method outperform the other?  \n",
    "- How do both approaches approximate the **KL-regularized RL objective** derived in [Christiano et al., 2017](https://arxiv.org/abs/1706.03741)?\n",
    "\n",
    "üìñ *References:*  \n",
    "- Rafailov et al., 2023. *Direct Preference Optimization: Your Language Model is Secretly a Reward Model.* [arXiv:2305.18290](https://arxiv.org/abs/2305.18290)\n",
    "<hr style=\"border:10px solid red\"> </hr>\n",
    "</font></h4>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DJq0nc5gOmL"
   },
   "source": [
    "<b><h4><font color='green'>\n",
    "<hr style=\"border:10px solid red\"> </hr>\n",
    "Answer 1: </b><br>\n",
    "\n",
    "Conceptually, these two methods approach policy optimization differently:\n",
    "- DPO does not use RL, and solves the standard RLHF problem using BCE, whereas GRPO is an RL algorithm derived from PPO.\n",
    "- GRPO uses a reward model to assign scores to sampled outputs, whereas PPO adjusts an implicit reward.\n",
    "In practical terms:\n",
    "- Both algorithms are efficient and computationally lightweight. GRPO significantly reduces training resources and memory consumption compared to PPO, and DPO simplifies learning by eliminating the need to sample from the language model during the fine-tuning phase.\n",
    "\n",
    "Regarding the approximation of the KL-regularized RL objective, GRPO approximates it by simplifying the calculation of the RL advantage while maintaining the RL policy optimization framework. It eliminates the value model by estimating the baseline from group scores (the average reward of multiple sampled outputs for the same question). The advantage is then calculated based on the relative rewards of outputs within each group.\n",
    "DPO approximates it using an analytical and direct method, thus still eliminating the need for an explicit reward model and a complex RL optimization algorithm.\n",
    "\n",
    "<hr style=\"border:10px solid red\"> </hr>\n",
    "</font></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10CojP_of_MM"
   },
   "source": [
    "<b><h4><font color='red'>\n",
    "<hr style=\"border:10px solid red\"> </hr>\n",
    "Question 2: </b><br>\n",
    "\n",
    "- Why can **reward model overfitting** or **reward hacking** occur in reinforcement fine-tuning?  \n",
    "- How do DPO and GRPO attempt to mitigate this without explicit online reward models?  \n",
    "- Discuss the role of the **reference model** in maintaining stability.\n",
    "<hr style=\"border:10px solid red\"> </hr>\n",
    "</font></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sPsmM7wOgPsQ"
   },
   "source": [
    "<b><h4><font color='green'>\n",
    "<hr style=\"border:10px solid red\"> </hr>\n",
    "Answer 2: </b><br>\n",
    "\n",
    "These problems arise for several reasons:\n",
    "\n",
    "- First, there may be a discrepancy between the approximation model and the human reward, which can lead to overfitting. The reward model is an approximation and therefore prone to inaccuracy. In addition, there may be over-optimization of the approximation. If the reward model is not perfect, the reinforcement learning algorithm can become unstable and stray too far from the initial distribution. When the RL agent maximizes this inaccurate reward function, it can identify gaps in the reward model (even small ones) and exploit them intensively, leading to the generation of bizarre and undesirable behaviors (reward hacking).\n",
    "- This reward hacking stems from the non-stationarity of the occupancy distribution: if there is a distribution shift between the data on which the reward model is accurate and the new states explored by the policy, optimization can become unstable. For example, offline training can cause an agent in a game like Pong to avoid losing points without trying to score any, resulting in extremely long and repetitive exchanges (ad infinitum) that do not correspond to the actual game objective.\n",
    "\n",
    "To counter reward hacking and instability, classic RLHF methods incorporate regularization:\n",
    "\n",
    "- Regularization by KL Divergence: this term prevents the policy from deviating too far from the reference policy. This mechanism aims to maintain diversity in generation and prevent mode collapse toward a single high-reward response, thereby preventing the model from exploiting weaknesses in the reward model too aggressively.\n",
    "- Experiments have shown that human feedback must be intertwined with RL learning (online training), rather than provided statically, to prevent the model from exploiting weaknesses in the reward model.\n",
    "This shows us that the reference model is crucial for maintaining stability and alignment. In both approaches,\n",
    "$\\pi_{ref}$ is typically the model refined by supervised learning (SFT). It represents an already acceptable policy that serves as a stable starting point. Its main role is to introduce a proximity constraint (via the KL term), ensuring that the optimized policy remains close to the distribution of the initial training data, thus preventing instability, loss of generative diversity, and mode collapse toward single high-reward responses. DPO achieves this stabilization implicitly and analytically by making the reference model an integral part of the reward definition, while GRPO uses it as an explicit KL penalty term in the reward maximization objective.\n",
    "\n",
    "<hr style=\"border:10px solid red\"> </hr>\n",
    "</font></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6NpkzPMgJh-"
   },
   "source": [
    "<b><h4><font color='red'>\n",
    "<hr style=\"border:10px solid red\"> </hr>\n",
    "Question 3: </b><br>\n",
    "\n",
    "- In the GSM8K setup, we used a simple binary reward for **format** and **correctness**.  \n",
    "  - What are the limitations of such sparse rewards?  \n",
    "  - How could you design a **richer, smoother** reward signal for math reasoning?\n",
    "<hr style=\"border:10px solid red\"> </hr>\n",
    "</font></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAl8OLepgRDO"
   },
   "source": [
    "<b><h4><font color='green'>\n",
    "<hr style=\"border:10px solid red\"> </hr>\n",
    "Answer 3: </b><br>\n",
    "\n",
    "A binary reward (success or failure) is an example of outcome-based supervision:\n",
    "\n",
    "- Insufficient learning signal: A sparse reward only provides a learning signal at the very end of the output sequence. In complex mathematical reasoning tasks such as GSM8K, where the solution involves a chain-of-thought or step-by-step reasoning, this end signal is insufficient and ineffective for supervising the policy.\n",
    "- Difficulty attributing credit: The model has difficulty determining which intermediate step in a long reasoning sequence led to the final success or failure, a problem known as the credit assignment problem in reinforcement learning.\n",
    "\n",
    "One solution could be process supervision, calculating the advantage of each token based on the sum of the normalized rewards of the following steps.\n",
    "\n",
    "<hr style=\"border:10px solid red\"> </hr>\n",
    "</font></h4>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}